{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset,  random_split\n",
    "from torch.optim import Adam\n",
    "from parameter import *\n",
    "from VAE_Model import *\n",
    "import joblib\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "rng = np.random.default_rng()\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "Properties = pd.read_csv('files/Data/Properties.csv')\n",
    "Compositions = pd.read_csv('files/Data/Compositions.csv')\n",
    "\n",
    "'''\n",
    "Properties indices:\n",
    " 0: 'Density'\n",
    " 1: 'Young's modulus'\n",
    " 2: 'Flexural modulus'\n",
    " 3: 'Shear modulus'\n",
    " 4: 'Bulk modulus'\n",
    " 5: 'Poisson's ratio'\n",
    " 6: 'Melting point'\n",
    " 7: 'Thermal conductivity'\n",
    " 8: 'Specific heat capacity'\n",
    " 9: 'Thermal expansion coefficient'\n",
    "10: 'Latent heat of fusion'\n",
    "11: 'Electrical conductivity'\n",
    "12: 'Acoustic velocity'\n",
    "13: 'Average Atomic Weight'\n",
    "'''\n",
    "\n",
    "'''\n",
    "Compositions indices:\n",
    "  0: 'Ag (silver)'\n",
    "  1: 'Al (aluminum)'\n",
    "  2: 'As (arsenic)'\n",
    "  3: 'Au (gold)'\n",
    "  4: 'B (boron)'\n",
    "  5: 'Be (beryllium)'\n",
    "  6: 'BeO (beryllia)'\n",
    "  7: 'Bi (bismuth)'\n",
    "  8: 'C (carbon)'\n",
    "  9: 'Ca (calcium)'\n",
    " 10: 'Cd (cadmium)'\n",
    " 11: 'Ce (cerium)'\n",
    " 12: 'Co (cobalt)'\n",
    " 13: 'Cr (chromium)'\n",
    " 14: 'Cu (copper)'\n",
    " 15: 'Dy (dysprosium)'\n",
    " 16: 'Er (erbium)'\n",
    " 17: 'Eu (europium)'\n",
    " 18: 'Fe (iron)'\n",
    " 19: 'Ga (gallium)'\n",
    " 20: 'Gd (gadolinium)'\n",
    " 21: 'Ge (germanium)'\n",
    " 22: 'H (hydrogen)'\n",
    " 23: 'Hf (hafnium)'\n",
    " 24: 'Ho (holmium)'\n",
    " 25: 'In (indium)'\n",
    " 26: 'Ir (iridium)'\n",
    " 27: 'La (lanthanum)'\n",
    " 28: 'Li (lithium)'\n",
    " 29: 'Lu (lutetium)'\n",
    " 30: 'Mg (magnesium)'\n",
    " 31: 'Mn (manganese)'\n",
    " 32: 'Mo (molybdenum)'\n",
    " 33: 'N (nitrogen)'\n",
    " 34: 'Nb (niobium)'\n",
    " 35: 'Nd (neodymium)'\n",
    " 36: 'Ni (nickel)'\n",
    " 37: 'O (oxygen)'\n",
    " 38: 'O2 (oxygen gas)'\n",
    " 39: 'Os (osmium)'\n",
    " 40: 'P (phosphorus)'\n",
    " 41: 'Pb (lead)'\n",
    " 42: 'Pd (palladium)'\n",
    " 43: 'Pr (praseodymium)'\n",
    " 44: 'Pt (platinum)'\n",
    " 45: 'Re (rhenium)'\n",
    " 46: 'Rh (rhodium)'\n",
    " 47: 'Ru (ruthenium)'\n",
    " 48: 'S (sulfur)'\n",
    " 49: 'Sb (antimony)'\n",
    " 50: 'Sc (scandium)'\n",
    " 51: 'Se (selenium)'\n",
    " 52: 'Si (silicon)'\n",
    " 53: 'Sm (samarium)'\n",
    " 54: 'Sn (tin)'\n",
    " 55: 'Sr (strontium)'\n",
    " 56: 'Ta (tantalum)'\n",
    " 57: 'Tb (terbium)'\n",
    " 58: 'Te (tellurium)'\n",
    " 59: 'ThO2 (thoria)'\n",
    " 60: 'Ti (titanium)'\n",
    " 61: 'Tl (thallium)'\n",
    " 62: 'Tm (thulium)'\n",
    " 63: 'U (uranium)'\n",
    " 64: 'V (vanadium)'\n",
    " 65: 'Y (Yttrium)'\n",
    " 66: 'Yb (Ytterbium)'\n",
    " 67: 'W (Tungsten)'\n",
    " 68: 'Zn (Zinc)'\n",
    " 69: 'Zr (Zirconium)'\n",
    "'''\n",
    "\n",
    "scaler_y = joblib.load('files/Scalers/scaler_Properties.pkl')\n",
    "X = Compositions\n",
    "Y = Properties\n",
    "\n",
    "XX = X.values\n",
    "YY = scaler_y.transform(Y)\n",
    "\n",
    "\n",
    "XX = torch.tensor(XX, dtype=torch.float32)\n",
    "YY = torch.tensor(YY, dtype=torch.float32)\n",
    "\n",
    "dataset  = TensorDataset(XX,YY)\n",
    "\n",
    "num_train = len(dataset)\n",
    "split = int(np.floor(valid_size * num_train)) \n",
    "train_dataset, test_dataset = random_split(dataset = dataset, lengths = [num_train - split,split])\n",
    "train_loader = DataLoaderX(train_dataset, batch_size = batch_size, shuffle = True, pin_memory = True)\n",
    "test_loader = DataLoaderX(test_dataset, batch_size = test_batch_size, shuffle = True, pin_memory = True)\n",
    "\n",
    "\n",
    "vae = vaeModel().to(device)\n",
    "p_model = pModel().to(device)\n",
    "vae.load_state_dict(torch.load(savedModelFolder + '/model.pt'))\n",
    "p_model.load_state_dict(torch.load(savedModelFolder + '/p_model.pt'))\n",
    "\n",
    "\n",
    "vae.eval()\n",
    "p_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********************************\n",
    "# ******** Initialization *********\n",
    "# *********************************\n",
    "\n",
    "dataset = test_loader.dataset\n",
    "# Choose a random index\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "# Get the data at the random index\n",
    "x, c = dataset[random_index:random_index+1]\n",
    "opt_value = c.to(device)\n",
    "\n",
    "\n",
    "dataset  = TensorDataset(XX,YY)\n",
    "num_train = len(dataset)\n",
    "data_loader = DataLoaderX(dataset, batch_size = num_train, shuffle = False, pin_memory = True)\n",
    "\n",
    "optimization_method = ['Adam']\n",
    "opt_epoch = 100\n",
    "num_sample = 50\n",
    "Adam_lr = 1e-4\n",
    "trace_back = True\n",
    "recon_criterion = nn.MSELoss(reduction = 'sum')\n",
    "\n",
    "initial_z = torch.randn(num_sample, latent_dim, device=device)\n",
    "\n",
    "print(\"Number of initial guesses = \", len(initial_z))\n",
    "updated_z = np.zeros(initial_z.shape)\n",
    "predicted_c = np.zeros([len(initial_z), param_Dim])\n",
    "optimization = optimization_method[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8443e3e",
   "metadata": {},
   "source": [
    "# Initialize storage for predictions, ground truths, and compositions\n",
    "Properties_test_all = []                  # Corresponding true properties\n",
    "Properties_pred_best = []                 # Best predicted properties per sample\n",
    "composition_best = []           # Best predicted compositions per sample\n",
    "\n",
    "best_sample_pred = None\n",
    "\n",
    "for composition, properties in test_loader:\n",
    "    composition = composition.to(device)\n",
    "    properties = properties.to(device)\n",
    "\n",
    "    # Optimization settings\n",
    "    patience = 100\n",
    "    updated_z_np = np.zeros(initial_z.shape)\n",
    "    predicted_properties_np = np.zeros([len(initial_z), param_Dim])\n",
    "    updated_composition = np.zeros((num_sample, composition.shape[1]))\n",
    "\n",
    "    best_accuracy_np = np.zeros(num_sample)\n",
    "\n",
    "    for idx in range(num_sample):\n",
    "        es = 0\n",
    "        best_acc = 1e10\n",
    "\n",
    "        # Initialize latent vector for optimization\n",
    "        initial_guess_z = initial_z[idx, :].clone().reshape(1, initial_z.shape[-1]).requires_grad_()\n",
    "\n",
    "        # Choose Adam optimizer\n",
    "        opt = torch.optim.Adam([initial_guess_z])\n",
    "\n",
    "\n",
    "        for e in range(opt_epoch):\n",
    "            predicted_composition = vae.decoder(initial_guess_z)  # Decode latent vector\n",
    "            predicted_composition = refine_composition(predicted_composition)\n",
    "\n",
    "            inv_z_recon, inv_mu_recon, inv_std_recon = vae.encoder(predicted_composition)\n",
    "\n",
    "            # Predict properties using mean from VAE encoder\n",
    "            predicted_properties = p_model(inv_mu_recon)\n",
    "\n",
    "            # Compute loss using only selected conditional features\n",
    "            target_values = torch.tensor(properties)\n",
    "            loss = recon_criterion(predicted_properties[0, [0, 1, 5]], target_values[0, [0, 1, 5]])\n",
    "\n",
    "            # Backprop and optimization step\n",
    "            loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "            accuracy = loss.item()\n",
    "            stored_z = inv_z_recon.detach().numpy()\n",
    "            stored_properties = predicted_properties.detach().numpy()\n",
    "            stored_composition = predicted_composition.detach().numpy()\n",
    "\n",
    "\n",
    "            # Early stopping and best tracking\n",
    "            if loss.item() < best_acc:\n",
    "                best_acc = loss.item()\n",
    "\n",
    "                es = 0\n",
    "            else:\n",
    "                es += 1\n",
    "                if es > patience:\n",
    "                    break\n",
    "\n",
    "        # Store final results per sample\n",
    "        updated_z_np[idx, :] = stored_z\n",
    "        predicted_properties_np[idx, :] = stored_properties\n",
    "        updated_composition[idx, :] = stored_composition\n",
    "        best_accuracy_np[idx] = accuracy\n",
    "\n",
    "    # Sort all outputs by accuracy (ascending MSE)\n",
    "    sorted_indices = np.argsort(best_accuracy_np)\n",
    "    updated_z_np_sorted = updated_z_np[sorted_indices]\n",
    "    predicted_properties_np_sorted = predicted_properties_np[sorted_indices]\n",
    "    updated_composition_sorted = updated_composition[sorted_indices]\n",
    "    best_accuracy_sorted = best_accuracy_np[sorted_indices]\n",
    "\n",
    "    # Store predictions and compositions\n",
    "    Properties_pred_best.append(predicted_properties_np_sorted[0, :].reshape(1, -1))  # Best predicted properties\n",
    "    Properties_test_all.append(properties.cpu().detach().numpy())           # True properties\n",
    "    composition_best.append(updated_composition_sorted[0, :].reshape(1, -1))  # Best composition (raw)\n",
    "print(\"Optimization completed for all samples.\")\n",
    "\n",
    "# Concatenate all results\n",
    "\n",
    "Properties_test_all = np.concatenate(Properties_test_all, axis=0)\n",
    "Properties_pred_best = np.concatenate(Properties_pred_best, axis=0)\n",
    "composition_best = np.concatenate(composition_best, axis=0)\n",
    "\n",
    "# Inverse scale property predictions\n",
    "Properties_test_all = scaler_y.inverse_transform(Properties_test_all)\n",
    "Properties_pred_best = scaler_y.inverse_transform(Properties_pred_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoaderX(test_dataset, batch_size = 1, shuffle = True, pin_memory = True)\n",
    "# Initialize storage for predictions, ground truths, and compositions\n",
    "Properties_test_all = []                  # Store ground-truth material properties\n",
    "Properties_pred_best = []                 # Store best predicted properties from optimization\n",
    "composition_best = []                     # Store best refined compositions (decoded from latent)\n",
    "\n",
    "best_sample_pred = None  # Placeholder for best latent vector if needed later\n",
    "\n",
    "\n",
    "# Inference and optimization loop over test dataset\n",
    "for composition, properties in test_loader:\n",
    "    composition = composition.to(device)     # Input composition (not used directly in optimization)\n",
    "    properties = properties.to(device)       # Ground-truth material properties (target)\n",
    "\n",
    "    # Optimization settings\n",
    "    patience = 100                           # Early stopping patience\n",
    "    updated_z_np = np.zeros(initial_z.shape)                          # Optimized latent vectors\n",
    "    predicted_properties_np = np.zeros([len(initial_z), param_Dim])   # Predicted properties\n",
    "    updated_composition = np.zeros((num_sample, composition.shape[1]))# Refined compositions\n",
    "\n",
    "    best_accuracy_np = np.zeros(num_sample)   # Store best loss value per latent sample\n",
    "\n",
    "    # Loop through each latent sample\n",
    "    for idx in range(num_sample):\n",
    "        es = 0              # Early stopping counter\n",
    "        best_acc = 1e10     # Initialize best loss (MSE) for current latent sample\n",
    "\n",
    "        # Initialize latent vector for optimization\n",
    "        initial_guess_z = initial_z[idx, :].clone().reshape(1, initial_z.shape[-1]).requires_grad_()\n",
    "\n",
    "        # Choose optimizer (Adam)\n",
    "        opt = torch.optim.Adam([initial_guess_z])\n",
    "\n",
    "        # Run optimization loop\n",
    "        for e in range(opt_epoch):\n",
    "            predicted_composition = vae.decoder(initial_guess_z)           # Decode latent to composition\n",
    "            predicted_composition = refine_composition(predicted_composition)  # Round and normalize\n",
    "\n",
    "            inv_z_recon, inv_mu_recon, inv_std_recon = vae.encoder(predicted_composition)  # Re-encode\n",
    "\n",
    "            predicted_properties = p_model(inv_mu_recon)  # Predict properties using TF model\n",
    "\n",
    "            # Compute loss on selected conditional features [0, 1, 5]\n",
    "\n",
    "            target_values = torch.tensor(properties)\n",
    "            loss = recon_criterion(predicted_properties[0, [0, 1, 5]], target_values[0, [0, 1, 5]])\n",
    "\n",
    "            # Backpropagation and step\n",
    "            loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "\n",
    "            # Store intermediate results\n",
    "            accuracy = loss.item()\n",
    "            stored_z = inv_z_recon.detach().numpy()\n",
    "            stored_properties = predicted_properties.detach().numpy()\n",
    "            stored_composition = predicted_composition.detach().numpy()\n",
    "\n",
    "            # Early stopping logic and best result tracking\n",
    "            if loss.item() < best_acc:\n",
    "                best_acc = loss.item()\n",
    "                es = 0  # Reset counter if improvement\n",
    "            else:\n",
    "                es += 1\n",
    "                if es > patience:\n",
    "                    break\n",
    "\n",
    "        # Store final results for current latent sample\n",
    "        updated_z_np[idx, :] = stored_z\n",
    "        predicted_properties_np[idx, :] = stored_properties\n",
    "        updated_composition[idx, :] = stored_composition\n",
    "        best_accuracy_np[idx] = accuracy\n",
    "\n",
    "    # Sort all results by best accuracy (MSE ascending)\n",
    "    sorted_indices = np.argsort(best_accuracy_np)\n",
    "    updated_z_np_sorted = updated_z_np[sorted_indices]\n",
    "    predicted_properties_np_sorted = predicted_properties_np[sorted_indices]\n",
    "    updated_composition_sorted = updated_composition[sorted_indices]\n",
    "    best_accuracy_sorted = best_accuracy_np[sorted_indices]\n",
    "\n",
    "    # Save best predictions and compositions\n",
    "    Properties_pred_best.append(predicted_properties_np_sorted[0, :].reshape(1, -1))   # Best prediction\n",
    "    Properties_test_all.append(properties.cpu().detach().numpy())                      # Ground truth\n",
    "    composition_best.append(updated_composition_sorted[0, :].reshape(1, -1))           # Best composition\n",
    "\n",
    "print(\"Optimization completed for all samples.\")\n",
    "\n",
    "# Concatenate all results from batches\n",
    "Properties_test_all = np.concatenate(Properties_test_all, axis=0)\n",
    "Properties_pred_best = np.concatenate(Properties_pred_best, axis=0)\n",
    "composition_best = np.concatenate(composition_best, axis=0)\n",
    "\n",
    "# Inverse scale the predicted and true properties for final comparison\n",
    "Properties_test_all = scaler_y.inverse_transform(Properties_test_all)\n",
    "Properties_pred_best = scaler_y.inverse_transform(Properties_pred_best)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
