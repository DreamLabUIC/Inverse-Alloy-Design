{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset,  random_split\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from parameter import *\n",
    "from VAE_Model import *\n",
    "#from denoise_model import DenoiseNN, p_losses, sample, linear_beta_schedule, cosine_beta_schedule, compute_total_mse\n",
    "from denoise_model import DenoisingModel, diffusion_loss, sample_from_model, linear_beta_schedule, cosine_beta_schedule\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "rng = np.random.default_rng()\n",
    "np.random.seed(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Properties = pd.read_csv('files/Data/Properties.csv')\n",
    "Compositions = pd.read_csv('files/Data/Compositions.csv')\n",
    "\n",
    "'''\n",
    "Properties indices:\n",
    " 0: 'Density'\n",
    " 1: 'Young's modulus'\n",
    " 2: 'Flexural modulus'\n",
    " 3: 'Shear modulus'\n",
    " 4: 'Bulk modulus'\n",
    " 5: 'Poisson's ratio'\n",
    " 6: 'Melting point'\n",
    " 7: 'Thermal conductivity'\n",
    " 8: 'Specific heat capacity'\n",
    " 9: 'Thermal expansion coefficient'\n",
    "10: 'Latent heat of fusion'\n",
    "11: 'Electrical conductivity'\n",
    "12: 'Acoustic velocity'\n",
    "13: 'Average Atomic Weight'\n",
    "'''\n",
    "\n",
    "'''\n",
    "Compositions indices:\n",
    "  0: 'Ag (silver)'\n",
    "  1: 'Al (aluminum)'\n",
    "  2: 'As (arsenic)'\n",
    "  3: 'Au (gold)'\n",
    "  4: 'B (boron)'\n",
    "  5: 'Be (beryllium)'\n",
    "  6: 'BeO (beryllia)'\n",
    "  7: 'Bi (bismuth)'\n",
    "  8: 'C (carbon)'\n",
    "  9: 'Ca (calcium)'\n",
    " 10: 'Cd (cadmium)'\n",
    " 11: 'Ce (cerium)'\n",
    " 12: 'Co (cobalt)'\n",
    " 13: 'Cr (chromium)'\n",
    " 14: 'Cu (copper)'\n",
    " 15: 'Dy (dysprosium)'\n",
    " 16: 'Er (erbium)'\n",
    " 17: 'Eu (europium)'\n",
    " 18: 'Fe (iron)'\n",
    " 19: 'Ga (gallium)'\n",
    " 20: 'Gd (gadolinium)'\n",
    " 21: 'Ge (germanium)'\n",
    " 22: 'H (hydrogen)'\n",
    " 23: 'Hf (hafnium)'\n",
    " 24: 'Ho (holmium)'\n",
    " 25: 'In (indium)'\n",
    " 26: 'Ir (iridium)'\n",
    " 27: 'La (lanthanum)'\n",
    " 28: 'Li (lithium)'\n",
    " 29: 'Lu (lutetium)'\n",
    " 30: 'Mg (magnesium)'\n",
    " 31: 'Mn (manganese)'\n",
    " 32: 'Mo (molybdenum)'\n",
    " 33: 'N (nitrogen)'\n",
    " 34: 'Nb (niobium)'\n",
    " 35: 'Nd (neodymium)'\n",
    " 36: 'Ni (nickel)'\n",
    " 37: 'O (oxygen)'\n",
    " 38: 'O2 (oxygen gas)'\n",
    " 39: 'Os (osmium)'\n",
    " 40: 'P (phosphorus)'\n",
    " 41: 'Pb (lead)'\n",
    " 42: 'Pd (palladium)'\n",
    " 43: 'Pr (praseodymium)'\n",
    " 44: 'Pt (platinum)'\n",
    " 45: 'Re (rhenium)'\n",
    " 46: 'Rh (rhodium)'\n",
    " 47: 'Ru (ruthenium)'\n",
    " 48: 'S (sulfur)'\n",
    " 49: 'Sb (antimony)'\n",
    " 50: 'Sc (scandium)'\n",
    " 51: 'Se (selenium)'\n",
    " 52: 'Si (silicon)'\n",
    " 53: 'Sm (samarium)'\n",
    " 54: 'Sn (tin)'\n",
    " 55: 'Sr (strontium)'\n",
    " 56: 'Ta (tantalum)'\n",
    " 57: 'Tb (terbium)'\n",
    " 58: 'Te (tellurium)'\n",
    " 59: 'ThO2 (thoria)'\n",
    " 60: 'Ti (titanium)'\n",
    " 61: 'Tl (thallium)'\n",
    " 62: 'Tm (thulium)'\n",
    " 63: 'U (uranium)'\n",
    " 64: 'V (vanadium)'\n",
    " 65: 'Y (Yttrium)'\n",
    " 66: 'Yb (Ytterbium)'\n",
    " 67: 'W (Tungsten)'\n",
    " 68: 'Zn (Zinc)'\n",
    " 69: 'Zr (Zirconium)'\n",
    "'''\n",
    "\n",
    "\n",
    "scaler_y = joblib.load('files/Scalers/scaler_Properties.pkl')\n",
    "X = Compositions\n",
    "Y = Properties\n",
    "\n",
    "XX = X.values\n",
    "YY = scaler_y.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = torch.tensor(XX, dtype=torch.float32)\n",
    "YY = torch.tensor(YY, dtype=torch.float32)\n",
    "\n",
    "dataset  = TensorDataset(XX,YY)\n",
    "\n",
    "num_train = len(dataset)\n",
    "split = int(np.floor(valid_size * num_train)) \n",
    "train_dataset, test_dataset = random_split(dataset = dataset, lengths = [num_train - split,split])\n",
    "train_loader = DataLoaderX(train_dataset, batch_size = batch_size, shuffle = True, pin_memory = True)\n",
    "test_loader = DataLoaderX(test_dataset, batch_size = test_batch_size, shuffle = True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = vaeModel().to(device)\n",
    "p_model = pModel().to(device)\n",
    "vae.load_state_dict(torch.load(savedModelFolder + '/model.pt'))\n",
    "p_model.load_state_dict(torch.load(savedModelFolder + '/p_model.pt'))\n",
    "\n",
    "\n",
    "vae.eval()\n",
    "p_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define beta schedule\n",
    "betas = linear_beta_schedule(timesteps=timesteps)  # Or cosine_beta_schedule(timesteps=timesteps)\n",
    "\n",
    "# Define alphas and related variables\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "\n",
    "# Intermediate values for the model\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# Posterior variance computation\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "# Initialize DenoiseNN model\n",
    "# Initialize DenoisingModel\n",
    "\n",
    "denoise_model = DenoisingModel(\n",
    "    z_dim=latent_dim,           # Dimensionality of noisy input\n",
    "    hidden_dim=hidden_dim_denoise,  # Hidden layer size\n",
    "    depth=n_layers_denoise,     # Number of MLP layers\n",
    "    cond_in=n_properties,       # Conditioning input dimension\n",
    "    cond_dim=dim_condition      # Projected conditioning vector dimension\n",
    ").to(device)\n",
    "\n",
    "# Optimizer and scheduler setup\n",
    "optimizer = torch.optim.Adam(denoise_model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "# Print number of trainable parameters\n",
    "trainable_params_diff = sum(p.numel() for p in denoise_model.parameters() if p.requires_grad)\n",
    "print(\"Number of Diffusion model's trainable parameters: \" + str(trainable_params_diff))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_denoiser:\n",
    "    # Train denoising model\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(1, epochs_denoise + 1):\n",
    "        denoise_model.train()\n",
    "        train_loss_all = 0\n",
    "        train_count = 0\n",
    "\n",
    "        for data in train_loader:\n",
    "            composition = data[0].to(device)\n",
    "            properties = data[1].to(device)\n",
    "            conditional_properties = properties[:, [0, 1, 5]]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                z_g, mu, std = vae.encoder(composition)\n",
    "\n",
    "            t = torch.randint(0, timesteps, (z_g.size(0),), device=device).long()\n",
    "            loss = diffusion_loss(denoise_model, z_g, t, conditional_properties,\n",
    "                                  sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod, loss_mode=\"l2\")\n",
    "\n",
    "            loss.backward()\n",
    "            train_loss_all += z_g.size(0) * loss.item()\n",
    "            train_count += z_g.size(0)\n",
    "            optimizer.step()\n",
    "\n",
    "        denoise_model.eval()\n",
    "        val_loss_all = 0\n",
    "        val_count = 0\n",
    "\n",
    "        for data in test_loader:\n",
    "            composition = data[0].to(device)\n",
    "            properties = data[1].to(device)\n",
    "            conditional_properties = properties[:, [0, 1, 5]]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                z_g, mu, std = vae.encoder(composition)\n",
    "\n",
    "            t = torch.randint(0, timesteps, (z_g.size(0),), device=device).long()\n",
    "            loss = diffusion_loss(denoise_model, z_g, t, conditional_properties,\n",
    "                                  sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod, loss_mode=\"l2\")\n",
    "\n",
    "            val_loss_all += z_g.size(0) * loss.item()\n",
    "            val_count += z_g.size(0)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch {epoch:03d} | Train Loss: {train_loss_all / train_count:.5f} | Val Loss: {val_loss_all / val_count:.5f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if best_val_loss >= val_loss_all:\n",
    "            best_val_loss = val_loss_all\n",
    "            torch.save({\n",
    "                'state_dict': denoise_model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }, savedModelFolder + '/denoise_model1.pth.tar')\n",
    "\n",
    "else:\n",
    "    checkpoint = torch.load(savedModelFolder + '/denoise_model1.pth.tar')\n",
    "    denoise_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "denoise_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(savedModelFolder +'/denoise_model.pth.tar')\n",
    "denoise_model.load_state_dict(checkpoint['state_dict'])\n",
    "denoise_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoaderX(test_dataset, batch_size = 1, shuffle = True, pin_memory = True)\n",
    "train_loader = DataLoaderX(train_dataset, batch_size = 1, shuffle = True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference step \n",
    "\n",
    "c_pred_all = []  # Store predicted properties\n",
    "c_test_all = []  # Store ground-truth properties\n",
    "refined_compositions_all = []  # Store best refined compositions\n",
    "\n",
    "best_sample_pred = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for composition, properties in test_loader:\n",
    "        composition = composition.to(device)  # Input composition \n",
    "        properties = properties.to(device)    # Ground truth material properties\n",
    "\n",
    "        conditional_properties = properties[:, [0, 1, 5]]  # Selected conditional features\n",
    "        y_cond = conditional_properties.repeat(50, 1).to(device)  # Expand for sampling\n",
    "\n",
    "        batch_size = y_cond.size(0)\n",
    "\n",
    "        # Generate samples from denoising model conditioned on selected properties\n",
    "        samples = sample_from_model(\n",
    "            denoise_model, y_cond,\n",
    "            z_dim=latent_dim,\n",
    "            n_steps=timesteps,\n",
    "            beta_sched=betas,\n",
    "            batch_sz=batch_size\n",
    "        )\n",
    "        samples_np = samples[-1]  # Get final time step \n",
    "\n",
    "        min_mse = float('inf')  # Initialize minimum MSE\n",
    "        best_predicted_composition = None\n",
    "\n",
    "        for sample0 in samples_np:\n",
    "            sample0 = sample0.reshape(1, 15)  # Reshape latent vector\n",
    "\n",
    "            # Decode latent vector into composition\n",
    "            predicted_composition = vae.decoder(sample0)\n",
    "\n",
    "            # Refine composition (round and redistribute tiny values)\n",
    "            predicted_composition = refine_composition(predicted_composition)\n",
    "\n",
    "            # Re-encode refined composition to get latent mean\n",
    "            z_g, mean, std = vae.encoder(predicted_composition)\n",
    "\n",
    "            # Predict properties using TensorFlow model\n",
    "            y_predicted = p_model(mean)\n",
    "\n",
    "            # Convert prediction to PyTorch tensor for MSE calculation\n",
    "            y_predicted_tensor = torch.tensor(y_predicted, dtype=torch.float32, device=device)\n",
    "\n",
    "            # Compute MSE between predicted and true conditional properties\n",
    "            mse_value = compute_total_mse(\n",
    "                properties.reshape(-1, 14)[:, [0, 1, 5]],\n",
    "                y_predicted_tensor[:, [0, 1, 5]]\n",
    "            )\n",
    "\n",
    "            # Update best sample if current is better\n",
    "            if mse_value < min_mse:\n",
    "                min_mse = mse_value\n",
    "                best_sample_pred = torch.tensor(sample0, device=device)\n",
    "                best_y_predicted_tensor = y_predicted_tensor.clone()\n",
    "                best_predicted_composition = predicted_composition.clone()\n",
    "\n",
    "        # Save predictions and ground truth for the current batch\n",
    "        c_pred_all.append(best_y_predicted_tensor.cpu().numpy())\n",
    "        c_test_all.append(properties.cpu().detach().numpy())\n",
    "        refined_compositions_all.append(best_predicted_composition.cpu().numpy())\n",
    "\n",
    "# Concatenate all predictions and labels\n",
    "c_pred_all = np.concatenate(c_pred_all, axis=0)\n",
    "c_test_all = np.concatenate(c_test_all, axis=0)\n",
    "refined_compositions_all = np.concatenate(refined_compositions_all, axis=0)\n",
    "\n",
    "# Inverse scale the predicted and true properties\n",
    "c_pred_all = scaler_y.inverse_transform(c_pred_all)\n",
    "c_test_all = scaler_y.inverse_transform(c_test_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
